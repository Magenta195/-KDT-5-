{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - konlpy\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/osx-arm64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip3 install konlpy # 파이썬 3.x 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def preprocess_data(text):\n",
    "    # 정규식을 사용하여 특수문자 제거\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # 불필요한 공백 제거\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # 소문자로 변환\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 자음으로만 구성된 부분 삭제 해야 하나..?\n",
    "    \n",
    "    # 토큰화\n",
    "    okt = Okt()\n",
    "    tokens = okt.morphs(text)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "train_data = pd.read_csv('/Users/inho/KDT_AI/study/project/2nd_textClassification/dataset/train.csv')\n",
    "test_data = pd.read_csv('/Users/inho/KDT_AI/study/project/2nd_textClassification/dataset/test.csv')\n",
    "\n",
    "# 텍스트 전처리\n",
    "train_data['text'] = train_data['text'].apply(preprocess_data)\n",
    "test_data['text'] = test_data['text'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[유소영, 비호감, 성형, 아줌마]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[나오지마라, 썅]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[식상하고, 지긋지긋했는데, 잘, 끝나네, 오예, 소리, 벗고, 빤스질러]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[성희롱, 당할, 얼굴, 이, 아닌데, ㅋㅋㅋ]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[끝, 까지, 해보자, 쪽, 파리, 원숭이, 자, 한, 쓰레기, 당]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[그냥, 이쁘다, 해주면되, 지, 악플, 들, 은, 진짜, 으, 휴, 대부분, 다,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[어우, 지겨워, 성형, 한, 애, 기사, 좀, 그만, 올려라, ㅉㅉ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[버핏, 은, 틀, 딱이라, 새로운, 걸, 못, 받아들여서, 그렇지]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[전라도, 가, 일본, 인, 선조, 잖아요, 진짜, 토착, 왜구, 죠]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[못, 생기, 고, 못, 난, 것, 들, 은, 혼자, 살아라, 너, 덜, 은, 쳐다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[우리, 북조선, 칭, 구들, 과, 좌빨, 들]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[저런, 니미, 봉, 다리, 를, 거, 시기, 혀, 벌고, 싶다]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[꼰대들, 다, 모였구만]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[틀, 딱, 쩝쩝, 이, 들, 쌍, 팔, 년도, 식, 빨갱이, 팔이, 안, 하냐, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[얼른, 니, 같은, 사나이, 한테, 시집, 가가, 떡, 두꺼비, 같은, 아들, 래...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[남자나이, 많고, 여자, 어리면, 뭐라안하면서, 여자, 가, 나이, 가, 많으면,...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>[간신, 호동, 이, 넌, 졸라, 간신쎅히, 아, 왕, 이, 되고싶은, 간신, 쎅히...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[오늘, 아, 형, 씹, 노잼]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>[문과, 들, 어떻, 게, 든, 쉴드치네, 적폐, 과목, 생, 윤사, ㅋㅋ]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>[암컷, 들, 은, 거, 시기, 가, 잘, 팔려야, 됨]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               text  label\n",
       "0    0                                [유소영, 비호감, 성형, 아줌마]      1\n",
       "1    1                                         [나오지마라, 썅]      3\n",
       "2    2          [식상하고, 지긋지긋했는데, 잘, 끝나네, 오예, 소리, 벗고, 빤스질러]      6\n",
       "3    3                         [성희롱, 당할, 얼굴, 이, 아닌데, ㅋㅋㅋ]      5\n",
       "4    4             [끝, 까지, 해보자, 쪽, 파리, 원숭이, 자, 한, 쓰레기, 당]      0\n",
       "5    5  [그냥, 이쁘다, 해주면되, 지, 악플, 들, 은, 진짜, 으, 휴, 대부분, 다,...      5\n",
       "6    6            [어우, 지겨워, 성형, 한, 애, 기사, 좀, 그만, 올려라, ㅉㅉ]      1\n",
       "7    7             [버핏, 은, 틀, 딱이라, 새로운, 걸, 못, 받아들여서, 그렇지]      4\n",
       "8    8            [전라도, 가, 일본, 인, 선조, 잖아요, 진짜, 토착, 왜구, 죠]      0\n",
       "9    9  [못, 생기, 고, 못, 난, 것, 들, 은, 혼자, 살아라, 너, 덜, 은, 쳐다...      1\n",
       "10  10                         [우리, 북조선, 칭, 구들, 과, 좌빨, 들]      2\n",
       "11  11               [저런, 니미, 봉, 다리, 를, 거, 시기, 혀, 벌고, 싶다]      3\n",
       "12  12                                     [꼰대들, 다, 모였구만]      4\n",
       "13  13  [틀, 딱, 쩝쩝, 이, 들, 쌍, 팔, 년도, 식, 빨갱이, 팔이, 안, 하냐, ...      2\n",
       "14  14  [얼른, 니, 같은, 사나이, 한테, 시집, 가가, 떡, 두꺼비, 같은, 아들, 래...      6\n",
       "15  15  [남자나이, 많고, 여자, 어리면, 뭐라안하면서, 여자, 가, 나이, 가, 많으면,...      6\n",
       "16  16  [간신, 호동, 이, 넌, 졸라, 간신쎅히, 아, 왕, 이, 되고싶은, 간신, 쎅히...      3\n",
       "17  17                                  [오늘, 아, 형, 씹, 노잼]      3\n",
       "18  18         [문과, 들, 어떻, 게, 든, 쉴드치네, 적폐, 과목, 생, 윤사, ㅋㅋ]      0\n",
       "19  19                    [암컷, 들, 은, 거, 시기, 가, 잘, 팔려야, 됨]      5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘 사전 구축\n",
    "vocab = {}\n",
    "for text in train_data['text']:\n",
    "    for token in text:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수 정의\n",
    "def tokenizer(text):\n",
    "    return [vocab[token] for token in text if token in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 인덱스로 변환\n",
    "train_data['text'] = train_data['text'].apply(tokenizer)\n",
    "test_data['text'] = test_data['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[15, 16, 17, 18, 19, 20]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[21, 22, 23, 24, 25, 26, 27, 28, 29, 30]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 4...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[45, 46, 3, 28, 47, 48, 49, 50, 51, 52]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[53, 37, 54, 55, 56, 57, 58, 59, 60]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[61, 62, 63, 64, 65, 66, 38, 67, 68, 69]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[58, 70, 71, 58, 72, 73, 36, 37, 74, 75, 76, 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[80, 81, 82, 83, 84, 85, 36]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[86, 87, 88, 89, 90, 91, 92, 93, 94, 95]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[96, 42, 97]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[54, 98, 99, 18, 36, 100, 101, 102, 103, 104, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[108, 109, 110, 111, 112, 113, 114, 115, 116, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[124, 125, 43, 126, 127, 43, 62, 128, 62, 129,...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>[139, 140, 18, 141, 142, 143, 144, 145, 18, 14...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[150, 144, 151, 152, 153]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>[154, 36, 155, 156, 157, 158, 159, 160, 161, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>[164, 36, 37, 91, 92, 62, 9, 165, 166]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               text  label\n",
       "0    0                                       [1, 2, 3, 4]      1\n",
       "1    1                                             [5, 6]      3\n",
       "2    2                      [7, 8, 9, 10, 11, 12, 13, 14]      6\n",
       "3    3                           [15, 16, 17, 18, 19, 20]      5\n",
       "4    4           [21, 22, 23, 24, 25, 26, 27, 28, 29, 30]      0\n",
       "5    5  [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 4...      5\n",
       "6    6            [45, 46, 3, 28, 47, 48, 49, 50, 51, 52]      1\n",
       "7    7               [53, 37, 54, 55, 56, 57, 58, 59, 60]      4\n",
       "8    8           [61, 62, 63, 64, 65, 66, 38, 67, 68, 69]      0\n",
       "9    9  [58, 70, 71, 58, 72, 73, 36, 37, 74, 75, 76, 7...      1\n",
       "10  10                       [80, 81, 82, 83, 84, 85, 36]      2\n",
       "11  11           [86, 87, 88, 89, 90, 91, 92, 93, 94, 95]      3\n",
       "12  12                                       [96, 42, 97]      4\n",
       "13  13  [54, 98, 99, 18, 36, 100, 101, 102, 103, 104, ...      2\n",
       "14  14  [108, 109, 110, 111, 112, 113, 114, 115, 116, ...      6\n",
       "15  15  [124, 125, 43, 126, 127, 43, 62, 128, 62, 129,...      6\n",
       "16  16  [139, 140, 18, 141, 142, 143, 144, 145, 18, 14...      3\n",
       "17  17                          [150, 144, 151, 152, 153]      3\n",
       "18  18  [154, 36, 155, 156, 157, 158, 159, 160, 161, 1...      0\n",
       "19  19             [164, 36, 37, 91, 92, 62, 9, 165, 166]      5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "\n",
    "        # 길이가 max_length가 넘지 않도록 자르고, 모자라면 padding 추가\n",
    "        text = text[:self.max_length] + [0] * (self.max_length - len(text))\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(text, dtype=torch.long),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "max_length = 128\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n",
    "train_dataset = HateSpeechDataset(train_texts, train_labels, max_length)\n",
    "val_dataset = HateSpeechDataset(val_texts, val_labels, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성 및 하이퍼파라미터 설정\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(vocab) + 1  # +1 for padding\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "num_classes = 7\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "\n",
    "# device 설정\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 정의\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, dropout_rate=0.5):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embedded = self.dropout(self.embedding(input_ids))\n",
    "        lstm_output, _ = self.lstm(embedded)\n",
    "        lstm_output = lstm_output[:, -1, :]\n",
    "        output = self.fc(self.dropout(lstm_output))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델, 옵티마이저, 손실함수 초기화\n",
    "model = BiLSTMClassifier(vocab_size, embedding_dim, hidden_dim, num_classes, dropout_rate).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 함수\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct_predictions += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), correct_predictions / len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_predictions += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), correct_predictions / len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습 및 검증\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc * 100:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_acc * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 테스트 데이터셋 준비\n",
    "test_dataset = HateSpeechDataset(test_data['text'], [0] * len(test_data), max_length)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 테스트 데이터셋 예측\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "\n",
    "        outputs = model(input_ids)\n",
    "        predictions.extend(outputs.argmax(1).tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 submission.csv 파일로 저장\n",
    "submission = pd.read_csv('submission.csv')\n",
    "submission['label'] = predictions\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('결과가 submission.csv 파일에 저장되었습니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7c2185bb365dcd588315b0847aad4bd6ab324800dd702a1689ac6f4f2b0594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
