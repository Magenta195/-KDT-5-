{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "NilSkBKhPthJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "4QmwmcXuPuLo"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "gb-ZmsUOBkXv"
      },
      "outputs": [],
      "source": [
        "pretrained_size = 224\n",
        "pretrained_means = [0.485, 0.456, 0.406]\n",
        "pretrained_stds= [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(pretrained_size, padding = 10),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means, \n",
        "                                                std = pretrained_stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.CenterCrop(pretrained_size),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means, \n",
        "                                                std = pretrained_stds)\n",
        "                       ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "l-89cb0XBkXz"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.ImageFolder(root = 'COVID_19_XRAY/train', \n",
        "                                  transform = train_transforms)\n",
        "\n",
        "test_data = datasets.ImageFolder(root = 'COVID_19_XRAY/test', \n",
        "                                 transform = test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9OQN9jG2P6p8"
      },
      "outputs": [],
      "source": [
        "# VALID_RATIO = 0.9\n",
        "\n",
        "# n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "# n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "# train_data, valid_data = data.random_split(train_data, \n",
        "#                                            [n_train_examples, n_valid_examples])\n",
        "\n",
        "# valid_data = copy.deepcopy(valid_data)\n",
        "# valid_data.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "LlF1vQHHRESs"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator = data.DataLoader(train_data, \n",
        "                                 shuffle = True, \n",
        "                                 batch_size = BATCH_SIZE)\n",
        "\n",
        "# valid_iterator = data.DataLoader(valid_data, \n",
        "#                                  batch_size = BATCH_SIZE)\n",
        "\n",
        "test_iterator = data.DataLoader(test_data, \n",
        "                                batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "dvkp1FEhBkYR"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ao_fIYG2BkYU"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                        \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "ygLIMUX6BkYX"
      },
      "outputs": [],
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "NsbYP0qrBkYZ"
      },
      "outputs": [],
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [2,2,2,2],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet34_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [3,4,6,3],\n",
        "                               channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "eFMwBDRVBkYc"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                               stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "            \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "                \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "            \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qIFUiYaCBkYg"
      },
      "outputs": [],
      "source": [
        "resnet50_config = ResNetConfig(block = Bottleneck,\n",
        "                               n_blocks = [3, 4, 6, 3],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet101_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 4, 23, 3],\n",
        "                                channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet152_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 8, 36, 3],\n",
        "                                channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "qsjfsiUhRZUD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mc/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/mc/opt/anaconda3/envs/kaggle/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "pretrained_model = models.resnet50(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Jf6xf2WVcNfY"
      },
      "outputs": [],
      "source": [
        "IN_FEATURES = pretrained_model.fc.in_features \n",
        "OUTPUT_DIM = 2\n",
        "\n",
        "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "9Ol3c207BkYz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrained_model.fc = fc\n",
        "model = ResNet(resnet50_config, OUTPUT_DIM)\n",
        "model.load_state_dict(pretrained_model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "4Cuqluk1ZNOW"
      },
      "outputs": [],
      "source": [
        "START_LR = 1e-3\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "fDjS7JvNBkZR"
      },
      "outputs": [],
      "source": [
        "FOUND_LR = 1e-3\n",
        "\n",
        "params = [\n",
        "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
        "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
        "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
        "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
        "          {'params': model.fc.parameters()}\n",
        "         ]\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(params, lr = FOUND_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "riS8zV2IxVMK"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = len(train_iterator)\n",
        "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
        "\n",
        "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
        "\n",
        "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
        "                                    max_lr = MAX_LRS,\n",
        "                                    total_steps = TOTAL_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        _, top_pred = y_pred.topk(1, 1)\n",
        "        top_pred = top_pred.t()\n",
        "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
        "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
        "        # correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
        "        acc_1 = correct_1 / batch_size\n",
        "        # acc_k = correct_k / batch_size\n",
        "    return acc_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Qr6Je0jMafsp"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc_1 = calculate_topk_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc_1 += acc_1.item()\n",
        "        # epoch_acc_5 += acc_5.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    # epoch_acc_5 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "85FW74KaakI_"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc_1 = calculate_topk_accuracy(y_pred, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc_1 += acc_1.item()\n",
        "            # epoch_acc_5 += acc_5.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    # epoch_acc_5 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "wkR6LzakamOV"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "lvoyX823apEN",
        "outputId": "0cb310cb-9016-4cca-dcbb-df2f04345e99"
      },
      "outputs": [],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc_1 = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
        "    # valid_loss, valid_acc_1 = evaluate(model, valid_iterator, criterion, device)\n",
        "        \n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'tut5-model.pt')\n",
        "    torch.save(model.state_dict(), 'tut5-model_resnet_50.pt')\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}%')\n",
        "    # print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fOla2axMBkZk",
        "outputId": "a8178c45-adaa-4b00-bf59-0a1de0eb4363"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut5-model_resnet_50.pt'))\n",
        "\n",
        "# test_loss, test_acc_1, test_acc_5 = evaluate(model, test_iterator, criterion, device)\n",
        "\n",
        "# print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlCBiYxQbi4s"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, iterator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            y_prob = F.softmax(y_pred, dim = -1)\n",
        "            top_pred = y_prob.argmax(1, keepdim = True)\n",
        "\n",
        "            images.append(x.cpu())\n",
        "            labels.append(y.cpu())\n",
        "            probs.append(y_prob.cpu())\n",
        "\n",
        "    images = torch.cat(images, dim = 0)\n",
        "    labels = torch.cat(labels, dim = 0)\n",
        "    probs = torch.cat(probs, dim = 0)\n",
        "\n",
        "    return images, labels, probs\n",
        "\n",
        "images, labels, probs = get_predictions(model, test_iterator)\n",
        "pred_labels = torch.argmax(probs, 1)\n",
        "test_y = ['normal' if label == 1 else 'covid' for label in pred_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "submission = pd.read_csv('COVID_19_XRAY/test/labels.csv')\n",
        "submission['label'] = test_y\n",
        "\n",
        "submission.to_csv(\"submission_resnet_50.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "5 - ResNet.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
